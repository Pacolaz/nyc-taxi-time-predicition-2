{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import  root_mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932baab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('../data/green_tripdata_2024-01.parquet')\n",
    "df_val = read_dataframe('../data/green_tripdata_2024-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217abdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO']  #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80926019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "\n",
    "dagshub.init(url=\"https://dagshub.com/Pacolaz/nyc-taxi-time-prediction\", mlflow=True)\n",
    "\n",
    "MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(experiment_name=\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e813acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2024-01\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2024-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ea518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  root_mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "\n",
    "def objective_rf(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Set model tag\n",
    "        mlflow.set_tag(\"model_family\", \"random_forest\")\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train RandomForest model\n",
    "        rf_model = RandomForestRegressor(\n",
    "            n_estimators=int(params['n_estimators']),\n",
    "            max_depth=int(params['max_depth']),\n",
    "            min_samples_split=int(params['min_samples_split']),\n",
    "            min_samples_leaf=int(params['min_samples_leaf']),\n",
    "            random_state=42\n",
    "        )\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on validation dataset\n",
    "        y_pred = rf_model.predict(X_val)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        # Log RMSE metric\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "# Define search space for RandomForest\n",
    "search_space_rf = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 100, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 5, 15, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 5, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 2, 1),\n",
    "}\n",
    "\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "with mlflow.start_run(run_name=\"Parent Random Forest\", nested=True):\n",
    "    best_params_rf = fmin(\n",
    "        fn=objective_rf,\n",
    "        space=search_space_rf,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=Trials()\n",
    "    )\n",
    "    \n",
    "    # Log best parameters\n",
    "    mlflow.log_params(best_params_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efeb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"8aaadd7a2926498f870f80b5e995d077\"\n",
    "run_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=run_uri,\n",
    "    name=\"nyc-taxi-model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fef6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow.sklearn.autolog()\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "def objective_gb(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Set model tag\n",
    "        mlflow.set_tag(\"model_family\", \"gradient_boosting\")\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train GradientBoosting model\n",
    "        gb_model = GradientBoostingRegressor(\n",
    "            n_estimators=int(params['n_estimators']),\n",
    "            max_depth=int(params['max_depth']),\n",
    "            min_samples_split=int(params['min_samples_split']),\n",
    "            min_samples_leaf=int(params['min_samples_leaf']),\n",
    "            learning_rate=float(params['learning_rate']),\n",
    "            random_state=42\n",
    "        )\n",
    "        gb_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on validation dataset\n",
    "        y_pred = gb_model.predict(X_val)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        # Log RMSE metric\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "# Define search space for GradientBoosting\n",
    "search_space_gb = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 100, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 5, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 2, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.1)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization for GradientBoosting\n",
    "with mlflow.start_run(run_name=\"Parent Gradient Boosting\", nested=True):\n",
    "    best_params_gb = fmin(\n",
    "        fn=objective_gb,\n",
    "        space=search_space_gb,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=Trials()\n",
    "    )\n",
    "    \n",
    "    # Log best parameters\n",
    "    mlflow.log_params(best_params_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"f079dad64aa34b2881dcacb8c59fec92\"\n",
    "run_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=run_uri,\n",
    "    name=\"nyc-taxi-model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba8c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "def objective_gb(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Set model tag\n",
    "        mlflow.set_tag(\"model_family\", \"gradient_boosting\")\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train GradientBoosting model\n",
    "        gb_model = GradientBoostingRegressor(\n",
    "            n_estimators=int(params['n_estimators']),\n",
    "            max_depth=int(params['max_depth']),\n",
    "            min_samples_split=int(params['min_samples_split']),\n",
    "            min_samples_leaf=int(params['min_samples_leaf']),\n",
    "            learning_rate=float(params['learning_rate']),\n",
    "            random_state=42\n",
    "        )\n",
    "        gb_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on validation dataset\n",
    "        y_pred = gb_model.predict(X_val)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        # Log RMSE metric\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "# Define search space for GradientBoosting\n",
    "search_space_gb = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 100, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 5, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 2, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.1)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization for GradientBoosting\n",
    "with mlflow.start_run(run_name=\"Parent Gradient Boosting\", nested=True):\n",
    "    best_params_gb = fmin(\n",
    "        fn=objective_gb,\n",
    "        space=search_space_gb,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=Trials()\n",
    "    )\n",
    "    \n",
    "    # Log best parameters\n",
    "    mlflow.log_params(best_params_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107100b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "def select_best_model(experiment_name):\n",
    "    try:\n",
    "        experiment = 0\n",
    "        \n",
    "        if experiment is None:\n",
    "            raise ValueError(f\"Experimento con nombre '{experiment_name}' no encontrado.\")\n",
    "        \n",
    "        experiment_id = experiment.experiment_id\n",
    "        \n",
    "        runs = mlflow.search_runs(\n",
    "            experiment_ids=[experiment_id],\n",
    "            run_view_type=ViewType.ACTIVE_ONLY\n",
    "        )\n",
    "\n",
    "        best_run = runs.loc[runs['metrics.rmse'].idxmin()]\n",
    "        best_run_id = best_run['run_id']\n",
    "\n",
    "        best_model_uri = f\"runs:/{best_run_id}/model\"\n",
    "        \n",
    "        mlflow.register_model(best_model_uri, \"Champion\")\n",
    "        \n",
    "        print(f\"El mejor modelo fue: {best_run_id} con el RMSE: {best_run['metrics.rmse']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al seleccionar el mejor modelo: {str(e)}\")\n",
    "\n",
    "select_best_model(\"nyc-taxi-experiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
